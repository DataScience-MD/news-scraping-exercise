{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MST698S_news-scraping-exercise.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/PurpleDin0/news-scraping-exercise/blob/master/Execution_Notebook.ipynb",
      "authorship_tag": "ABX9TyMtD2yPJ/3Cq4/WuxNolN1m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PurpleDin0/news-scraping-exercise/blob/master/Execution_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jIVlByg4YiE",
        "colab_type": "text"
      },
      "source": [
        "# MST 698S - Data Science Tools And Techniques \n",
        "# Bad Ozone Grasshoppers - News Scrapper Exercise\n",
        "\n",
        "Summary: \n",
        "\n",
        "Usage Details: This Notebook is desigened to be run in the [Google Colab environment](https://colab.research.google.com/). However, it should work in any Jupyter Notebooks or Jupyter Lab environment.  The main purpose of the notebook is to install relevant python libraries, execute the web scrapping code, and save the output to a cloud repository.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIUL-n5N6Q3i",
        "colab_type": "text"
      },
      "source": [
        "## Initialize the Environment \n",
        "1. Clone the github repo [located here](https://github.com/PurpleDin0/news-scraping-exercise).  \n",
        "2. Install all required dependancies.  This is best done by storing all dependices to a `requirements.txt` in the github repo file and running a `pip install` for using that file.  \n",
        "```\n",
        "!pip install -r requirements.txt\n",
        "```\n",
        "3. Install the webdrivers for selenium   \n",
        "this is needed as Google Colab does not have a web browser to drive selenium.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAx6SKzRtQ_j",
        "colab_type": "code",
        "outputId": "8323d294-2113-4a30-94e3-4b9b7a8edc9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "# Navigate the working directory in colab to \"/content\" \n",
        "%cd /content/\n",
        "# First clone the relevant github repo\n",
        "!git clone https://github.com/PurpleDin0/news-scraping-exercise.git\n",
        "# Navigate to the newly created repo folder\n",
        "%cd /content/news-scraping-exercise\n",
        "# install all required python libraries\n",
        "!pip install -r requirements.txt\n",
        "# Once installed make sure to restart the runtime (if needed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'news-scraping-exercise'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 36 (delta 15), reused 5 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (36/36), done.\n",
            "/content/news-scraping-exercise\n",
            "Collecting selenium==3.141.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 5.0MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/b7/34eec2fe5a49718944e215fde81288eec1fa04638aa3fb57c1c6cd0f98c3/beautifulsoup4-4.8.0-py3-none-any.whl (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.23.0)\n",
            "Collecting lxml==4.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/ba/a0e6866057fc0bbd17192925c1d63a3b85cf522965de9bc02364d08e5b84/lxml-4.5.0-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8MB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium==3.141.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Collecting soupsieve>=1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/05/cf/ea245e52f55823f19992447b008bcbb7f78efc5960d77f6c34b5b45b36dd/soupsieve-2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.23.0->-r requirements.txt (line 3)) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.23.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.23.0->-r requirements.txt (line 3)) (2020.4.5.1)\n",
            "Installing collected packages: selenium, soupsieve, beautifulsoup4, lxml\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed beautifulsoup4-4.8.0 lxml-4.5.0 selenium-3.141.0 soupsieve-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar9SZueTSguN",
        "colab_type": "code",
        "outputId": "36ada45f-b76f-499d-c6e3-9b74c8e50bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Install the Chromium webdriver so Selenium can work\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [1 InRelease 3,626 \r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Waiting for header\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Waiting for header\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [912 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [846 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [8,507 B]\n",
            "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,816 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [19.8 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,207 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,376 kB]\n",
            "Get:21 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [876 kB]\n",
            "Fetched 7,331 kB in 4s (1,849 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 54 not upgraded.\n",
            "Need to get 77.3 MB of archives.\n",
            "After this operation, 264 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 81.0.4044.138-0ubuntu0.18.04.1 [1,095 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 81.0.4044.138-0ubuntu0.18.04.1 [68.9 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 81.0.4044.138-0ubuntu0.18.04.1 [3,231 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 81.0.4044.138-0ubuntu0.18.04.1 [4,079 kB]\n",
            "Fetched 77.3 MB in 5s (15.4 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 144429 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_81.0.4044.138-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (81.0.4044.138-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_81.0.4044.138-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (81.0.4044.138-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_81.0.4044.138-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (81.0.4044.138-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_81.0.4044.138-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (81.0.4044.138-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (81.0.4044.138-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (81.0.4044.138-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (81.0.4044.138-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (81.0.4044.138-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkmccT65aWZI",
        "colab_type": "text"
      },
      "source": [
        "## Run the reuters news scrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIBFctbfvK7m",
        "colab_type": "code",
        "outputId": "6e863e91-f7e5-49ed-9fa5-4a2369c475c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "!python3 news_reuters.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting Reuters articles...\n",
            "Unable to decode...skipping article...\n",
            "Saving news object...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJuAL-4CacVi",
        "colab_type": "text"
      },
      "source": [
        "## Export the reuters news dump\n",
        "NOTE: the news dump is saved as a JSON as it is more secure then a pickle file\n",
        "* [ ] TODO: update code to use JSON instead of pickle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYtKLMugbR8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0hjNRUxc-jE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle_path = os.path.join(os.getcwd(), 'news_dump_object.pkl')\n",
        "df = pd.DataFrame(pd.read_pickle(pickle_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC8yCGjYdR6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_file_path = os.path.join(os.getcwd(), 'news_dump_object.json')\n",
        "#with open(save_path, 'wb') as json_file:\n",
        "df.to_json(json_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eNmw4hfTV3I",
        "colab_type": "code",
        "outputId": "f6009197-8ea3-4859-a195-b9a35b3e20df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OudHxI0vTvwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export all files to your google drive *CHANGE PATH to where you want to save the files\n",
        "!cp /content/news-scraping-exercise/news_dump_object* '/content/drive/My Drive/Colab Notebooks/Coursework/698S/news-scraping-exercise'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-flkmEIxQX7h",
        "colab_type": "text"
      },
      "source": [
        "#Advanced stuff we probably don't want to mess with\n",
        "The below sections are draft for using SSH and CLI Git commands to push and pull info to a github repo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTwBa0H0R4O-",
        "colab_type": "text"
      },
      "source": [
        "## Use pythongit library to programtically execute git commands\n",
        "https://gitpython.readthedocs.io/en/stable/tutorial.html#tutorial-label "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5BPyqo3kbk6",
        "colab_type": "code",
        "outputId": "dc928f99-c423-400d-d3d4-f1c7f9bc2968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "!pip install gitpython"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/33/917e6fde1cad13daa7053f39b7c8af3be287314f75f1b1ea8d3fe37a8571/GitPython-3.1.2-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 2.7MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.6MB/s \n",
            "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.5 gitpython-3.1.2 smmap-3.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkw1E1Akl4ZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import git\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX3kJESMmEcc",
        "colab_type": "code",
        "outputId": "2d10d9bc-87a4-4b7c-c820-13bdf4360db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%cd /content/news-scraping-exercise/\n",
        "repo = git.Repo() #initializes the repo in the current working directory\n",
        "print repo.git.add(json_file_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/news-scraping-exercise\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zT8tny6nrHw",
        "colab_type": "code",
        "outputId": "0171df7a-5762-4990-bff5-e70b9bb6df41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "print(repo.git.status())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch master\n",
            "Your branch is ahead of 'origin/master' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
            "\n",
            "\tmodified:   news_dump_object.pkl\n",
            "\tmodified:   news_reuters.py\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\tgeckodriver.log\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcB1dLcOmzuR",
        "colab_type": "code",
        "outputId": "0dbb5767-a815-4248-eec1-e860d36a00ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "repo.git.commit( m='updated JSON news dump with new articles' )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[master 565227e] updated JSON news dump with new articles\\n 1 file changed, 1 insertion(+)\\n create mode 100644 news_dump_object.json'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaGPkxkInV_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import git\n",
        "repo = git.Repo( '/home/me/repodir' )\n",
        "print repo.git.status()\n",
        "# checkout and track a remote branch\n",
        "print repo.git.checkout( 'origin/somebranch', b='somebranch' )\n",
        "# add a file\n",
        "print repo.git.add( 'somefile' )\n",
        "# commit\n",
        "print repo.git.commit( m='my commit message' )\n",
        "# now we are one commit ahead\n",
        "print repo.git.status()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1haNjyJQE2i",
        "colab_type": "text"
      },
      "source": [
        "## Create an SSH key to use in github\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs9dFNm8vACp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create an SSH key\n",
        "!ssh-keygen -t rsa -b 4096 -C \"Barney.Ales@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTKW5gJ7N18R",
        "colab_type": "text"
      },
      "source": [
        "## Push changes to github using Colab\n",
        "The below section loads an SSH key from google drive and then connects to git hub to push any modifications directly to the repo.\n",
        "  **NOTE: this section is not ready for prime time.\n",
        "* Main issue is the SSH commands are not executing or keeping the passphrase for the keys resident in memory.  This can be bypassed by running `!SSH /bin/bash/` then loading the SSH key using `ssh-add /root/.ssh/PurpleDin0_Colab_github.ssh`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bec8H5tP-hJT",
        "colab_type": "code",
        "outputId": "92c9bb4c-5296-4e16-a289-1791e0b95d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!git config --global user.email \"Barney.Ales@gmail.com\"\n",
        "!git config --global user.name \"PurpleDin0\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `\"'\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXfji8jSszfq",
        "colab_type": "code",
        "outputId": "7d8ce0e6-76cb-4d2c-e87f-f1cb4c574551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!git config --global -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "user.email=Barney.Ales@gmail.com\n",
            "user.name=PurpleDin0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvDudlw1wQqo",
        "colab_type": "code",
        "outputId": "8bc22b0c-9264-4414-e4b3-00f9b374bbc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#launch the SSH\n",
        "!eval \"$(ssh-agent -s)\"\n",
        "git push git@github.com:PurpleDin0/news-scraping-exercise.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Agent pid 4755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6TGj2kh7HC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ssh-agent /bin/bash"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6HZODB9wXNz",
        "colab_type": "code",
        "outputId": "96c2924e-28b3-4329-9dde-df9bfc10ab87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#Add your SSH private key to the ssh-agent. If you created your key with a different name, or if you are adding an existing key that has a different name, replace with the name of your private key file.\n",
        "!ssh-add /root/.ssh/id_rsa_PurpleDin0_Colab_github.ssh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Could not open a connection to your authentication agent.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K56wgSswz9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copy your SSH keys and config files from google drive into Colab workspace\n",
        "# [] code needs to be modified to move all files in one line (recursive cp)\n",
        "%mkdir ~/.ssh/\n",
        "!cp /content/drive/My\\ Drive/Secure/PurpleDin0_Colab_github.ssh ~/.ssh/\n",
        "!cp /content/drive/My\\ Drive/Secure/PurpleDin0_Colab_github.ssh ~/.ssh/\n",
        "!cp /content/drive/My\\ Drive/Secure/config ~/.ssh/\n",
        "%ls /root/.ssh/ -all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHD64PTq2NL4",
        "colab_type": "code",
        "outputId": "0ee34395-e99a-4300-8ca3-b7d1a7356faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "#ensure the ssh key folder contains the correct permisions \n",
        "!chmod 700 /root/.ssh/\n",
        "# Add the git server as a known ssh host\n",
        "!touch /root/.ssh/known_hosts\n",
        "!ssh-keyscan github.com >> /root/.ssh/known_hosts\n",
        "!chmod 644 /root/.ssh/known_hosts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# github.com:22 SSH-2.0-babeld-6d6fef33\n",
            "# github.com:22 SSH-2.0-babeld-6d6fef33\n",
            "# github.com:22 SSH-2.0-babeld-6d6fef33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W7bn3Uz4vNP",
        "colab_type": "text"
      },
      "source": [
        "Sources & references:  \n",
        "Using GIt with Colab via SSH - https://techsupportallbugs.wordpress.com/2018/06/05/using-git-with-colab-via-ssh/\n"
      ]
    }
  ]
}